{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting classy-classification\r\n",
      "  Downloading classy_classification-0.5-py3-none-any.whl (14 kB)\r\n",
      "Collecting fast-sentence-transformers==0.3.4\r\n",
      "  Downloading fast_sentence_transformers-0.3.4-py3-none-any.whl (21 kB)\r\n",
      "Requirement already satisfied: spacy[transformers]<4.0,>=3.0 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from classy-classification) (3.3.1)\r\n",
      "Collecting scikit-learn<2.0,>=1.0\r\n",
      "  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m30.5/30.5 MB\u001B[0m \u001B[31m26.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting sentence-transformers<3.0,>=2.0\r\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.0/86.0 kB\u001B[0m \u001B[31m16.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting onnxruntime<2.0,>=1.10\r\n",
      "  Downloading onnxruntime-1.13.1-cp310-cp310-manylinux_2_27_x86_64.whl (4.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/4.5 MB\u001B[0m \u001B[31m37.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting psutil<6.0.0,>=5.9.2\r\n",
      "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m280.2/280.2 kB\u001B[0m \u001B[31m22.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting onnx<2.0.0,>=1.12.0\r\n",
      "  Downloading onnx-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m22.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting scipy>=1.3.2\r\n",
      "  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m33.7/33.7 MB\u001B[0m \u001B[31m26.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting threadpoolctl>=2.0.0\r\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from scikit-learn<2.0,>=1.0->classy-classification) (1.23.4)\r\n",
      "Collecting joblib>=1.0.0\r\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m298.0/298.0 kB\u001B[0m \u001B[31m29.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from sentence-transformers<3.0,>=2.0->classy-classification) (4.20.1)\r\n",
      "Requirement already satisfied: tqdm in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from sentence-transformers<3.0,>=2.0->classy-classification) (4.64.1)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from sentence-transformers<3.0,>=2.0->classy-classification) (1.13.0)\r\n",
      "Collecting torchvision\r\n",
      "  Downloading torchvision-0.14.0-cp310-cp310-manylinux1_x86_64.whl (24.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.3/24.3 MB\u001B[0m \u001B[31m29.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nltk\r\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m48.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting sentencepiece\r\n",
      "  Using cached sentencepiece-0.1.97-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from sentence-transformers<3.0,>=2.0->classy-classification) (0.11.0)\r\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (0.4.1)\r\n",
      "Requirement already satisfied: jinja2 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (3.1.2)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (0.9.1)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (0.7.7)\r\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (0.6.1)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (2.0.6)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (2.28.1)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (1.0.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (21.3)\r\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (8.0.15)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (3.0.6)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (3.0.9)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (2.0.7)\r\n",
      "Requirement already satisfied: setuptools in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (65.5.0)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (3.3.0)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (1.0.1)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (2.4.3)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (1.8.2)\r\n",
      "Requirement already satisfied: spacy-transformers<1.2.0,>=1.1.2 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy[transformers]<4.0,>=3.0->classy-classification) (1.1.7)\r\n",
      "Requirement already satisfied: filelock in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers<3.0,>=2.0->classy-classification) (3.8.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers<3.0,>=2.0->classy-classification) (4.3.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers<3.0,>=2.0->classy-classification) (6.0)\r\n",
      "Collecting protobuf<=3.20.1,>=3.12.2\r\n",
      "  Downloading protobuf-3.20.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m42.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting flatbuffers\r\n",
      "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\r\n",
      "Collecting coloredlogs\r\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m8.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting sympy\r\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.5/6.5 MB\u001B[0m \u001B[31m37.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from packaging>=20.0->spacy[transformers]<4.0,>=3.0->classy-classification) (3.0.9)\r\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from pathy>=0.3.5->spacy[transformers]<4.0,>=3.0->classy-classification) (5.2.1)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]<4.0,>=3.0->classy-classification) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]<4.0,>=3.0->classy-classification) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]<4.0,>=3.0->classy-classification) (1.26.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]<4.0,>=3.0->classy-classification) (2022.9.24)\r\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]<4.0,>=3.0->classy-classification) (0.8.6)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers<3.0,>=2.0->classy-classification) (8.5.0.96)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers<3.0,>=2.0->classy-classification) (11.7.99)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers<3.0,>=2.0->classy-classification) (11.10.3.66)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers<3.0,>=2.0->classy-classification) (11.7.99)\r\n",
      "Requirement already satisfied: wheel in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers<3.0,>=2.0->classy-classification) (0.37.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers<3.0,>=2.0->classy-classification) (2022.10.31)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers<3.0,>=2.0->classy-classification) (0.12.1)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from typer<0.5.0,>=0.3.0->spacy[transformers]<4.0,>=3.0->classy-classification) (8.0.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/juanbermeo/anaconda3/envs/ATAI/lib/python3.10/site-packages (from jinja2->spacy[transformers]<4.0,>=3.0->classy-classification) (2.1.1)\r\n",
      "Collecting pillow!=8.3.*,>=5.3.0\r\n",
      "  Downloading Pillow-9.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m42.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting humanfriendly>=9.1\r\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.8/86.8 kB\u001B[0m \u001B[31m16.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting mpmath>=0.19\r\n",
      "  Downloading mpmath-1.2.1-py3-none-any.whl (532 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m532.6/532.6 kB\u001B[0m \u001B[31m32.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hBuilding wheels for collected packages: sentence-transformers\r\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=c842f4f48f55d2d48ba956b594f64647f86b7cb04f941e694f0824674ab6688d\r\n",
      "  Stored in directory: /home/juanbermeo/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\r\n",
      "Successfully built sentence-transformers\r\n",
      "Installing collected packages: sentencepiece, mpmath, flatbuffers, threadpoolctl, sympy, scipy, psutil, protobuf, pillow, joblib, humanfriendly, scikit-learn, onnx, nltk, coloredlogs, onnxruntime, torchvision, sentence-transformers, fast-sentence-transformers, classy-classification\r\n",
      "  Attempting uninstall: psutil\r\n",
      "    Found existing installation: psutil 5.9.0\r\n",
      "    Uninstalling psutil-5.9.0:\r\n",
      "      Successfully uninstalled psutil-5.9.0\r\n",
      "Successfully installed classy-classification-0.5 coloredlogs-15.0.1 fast-sentence-transformers-0.3.4 flatbuffers-22.10.26 humanfriendly-10.0 joblib-1.2.0 mpmath-1.2.1 nltk-3.7 onnx-1.12.0 onnxruntime-1.13.1 pillow-9.3.0 protobuf-3.20.1 psutil-5.9.4 scikit-learn-1.1.3 scipy-1.9.3 sentence-transformers-2.2.2 sentencepiece-0.1.97 sympy-1.11.1 threadpoolctl-3.1.0 torchvision-0.14.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install classy-classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import classy_classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('First Funnel - Train Examples.csv')\n",
    "df.set_index('Question type', inplace=True)\n",
    "df.sort_index(ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "train_dict = {}\n",
    "for cat_i, df_cat_i in df.groupby('Question type'):\n",
    "    train_dict[cat_i] = df_cat_i['Input text'].to_list()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "persist it to json file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "output_path = os.path.join('..', '..', 'setup_data', 'first_filter_train_examples.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(output_path, 'w') as fp:\n",
    "    json.dump(train_dict, fp, sort_keys=True, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spacy's middle model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['furniture' 'kitchen'] [0.46483467 0.53516533]\n",
      "{'furniture': 0.4648346710750303, 'kitchen': 0.5351653289249698}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = {\n",
    "    \"furniture\": [\"This text is about chairs.\",\n",
    "               \"Couches, benches and televisions.\",\n",
    "               \"I really need to get a new sofa.\"],\n",
    "    \"kitchen\": [\"There also exist things like fridges.\",\n",
    "                \"I hope to be getting a new stove today.\",\n",
    "                \"Do you also have some ovens.\"]\n",
    "}\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp.add_pipe(\n",
    "    \"text_categorizer\",\n",
    "    config={\n",
    "        \"data\": data,\n",
    "        \"model\": \"spacy\",\n",
    "        \"cat_type\": \"multi-label\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(nlp(\"I am looking for kitchen appliances.\")._.cats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train few-shot categorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "<classy_classification.classifiers.classy_spacy.classySpacyInternalFewShot at 0x7f8b1ec7fd30>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.add_pipe(\n",
    "    \"text_categorizer\",\n",
    "    config={\n",
    "        \"data\": train_dict,\n",
    "        \"model\": \"spacy\"\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conversation' 'Factual Question/Embedding/Crowdsourcing'\n",
      " 'Media Question' 'Recommendation Questions'] [0.16959642 0.28293407 0.12628045 0.42118907]\n",
      "{'Conversation': 0.16959641509573653, 'Factual Question/Embedding/Crowdsourcing': 0.2829340679385176, 'Media Question': 0.1262804474196118, 'Recommendation Questions': 0.42118906954613405}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(\"Hey, i am interested in a movie recomendation that is as good as The Goonies and Toy Story\")._.cats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conversation' 'Factual Question/Embedding/Crowdsourcing'\n",
      " 'Media Question' 'Recommendation Questions'] [0.65992502 0.22482746 0.08236993 0.03287759]\n",
      "{'Conversation': 0.6599250210440973, 'Factual Question/Embedding/Crowdsourcing': 0.22482746057270114, 'Media Question': 0.08236992624372713, 'Recommendation Questions': 0.032877592139474277}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(nlp(\"Hey how is it going\")._.cats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conversation' 'Factual Question/Embedding/Crowdsourcing'\n",
      " 'Media Question' 'Recommendation Questions'] [0.06518361 0.04043501 0.87013233 0.02424905]\n",
      "{'Conversation': 0.06518361222514099, 'Factual Question/Embedding/Crowdsourcing': 0.04043501102190481, 'Media Question': 0.8701323267631766, 'Recommendation Questions': 0.024249049989777383}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(\"hey would you be so kind to display picture Ali G\")._.cats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conversation' 'Factual Question/Embedding/Crowdsourcing'\n",
      " 'Media Question' 'Recommendation Questions'] [0.27453749 0.61499526 0.03647736 0.0739899 ]\n",
      "{'Conversation': 0.2745374861189631, 'Factual Question/Embedding/Crowdsourcing': 0.6149952554559426, 'Media Question': 0.036477362756375656, 'Recommendation Questions': 0.0739898956687187}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(\"I bet you have absolutely no idea who is the voice of Tanjirou in Kimetsu no Yaiba\")._.cats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "it's not that bad, but it is much better with the sentence-transformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using sentence-transformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found at: /home/juanbermeo/.cache/torch/sentence_transformers/sentence-transformers_paraphrase-multilingual-MiniLM-L12-v2/quantized_true.onnx\n",
      "['furniture' 'kitchen'] [0.14006391 0.85993609]\n",
      "{'furniture': 0.1400639084824182, 'kitchen': 0.8599360915175817}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import classy_classification\n",
    "\n",
    "data = {\n",
    "    \"furniture\": [\"This text is about chairs.\",\n",
    "               \"Couches, benches and televisions.\",\n",
    "               \"I really need to get a new sofa.\"],\n",
    "    \"kitchen\": [\"There also exist things like fridges.\",\n",
    "                \"I hope to be getting a new stove today.\",\n",
    "                \"Do you also have some ovens.\"]\n",
    "}\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\n",
    "    \"text_categorizer\",\n",
    "    config={\n",
    "        \"data\": data,\n",
    "        \"model\": \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        \"device\": \"gpu\",\n",
    "        \"cat_type\": \"multi-label\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(nlp(\"I am looking for kitchen appliances.\")._.cats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conversation' 'Factual Question/Embedding/Crowdsourcing'\n",
      " 'Media Question' 'Recommendation Questions'] [0.06383076 0.6337598  0.1241994  0.17821004]\n"
     ]
    },
    {
     "data": {
      "text/plain": "I am looking for kitchen appliances."
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"I am looking for kitchen appliances.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Let's try with our few examples of question types"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train few-shot categorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found at: /home/juanbermeo/.cache/torch/sentence_transformers/sentence-transformers_paraphrase-multilingual-MiniLM-L12-v2/quantized_true.onnx\n"
     ]
    },
    {
     "data": {
      "text/plain": "<classy_classification.classifiers.classy_spacy.classySpacyExternalFewShot at 0x7f8afa26d990>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\n",
    "    \"text_categorizer\",\n",
    "    config={\n",
    "        \"data\": train_dict,\n",
    "        \"model\": \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "        #\"device\": \"gpu\",\n",
    "        \"cat_type\": \"multi-label\"\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conversation' 'Factual Question/Embedding/Crowdsourcing'\n",
      " 'Media Question' 'Recommendation Questions'] [0.05190779 0.18905881 0.03160923 0.72742417]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Hey, i am interested in a movie recomendation that is as good as The Goonies and Toy Story"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"Hey, i am interested in a movie recomendation that is as good as The Goonies and Toy Story\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conversation' 'Factual Question/Embedding/Crowdsourcing'\n",
      " 'Media Question' 'Recommendation Questions'] [0.04603117 0.19062184 0.03005194 0.73329505]\n",
      "{'Conversation': 0.046031172799330396, 'Factual Question/Embedding/Crowdsourcing': 0.1906218359115138, 'Media Question': 0.03005194240328927, 'Recommendation Questions': 0.7332950488858668}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(\"Hey, i am interested in a movie recomendation that is as good as The Goonies and Toy Story\")._.cats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conversation' 'Factual Question/Embedding/Crowdsourcing'\n",
      " 'Media Question' 'Recommendation Questions'] [0.93933056 0.02474838 0.02455568 0.01136538]\n",
      "{'Conversation': 0.9393305623784225, 'Factual Question/Embedding/Crowdsourcing': 0.02474837841420033, 'Media Question': 0.024555676041556174, 'Recommendation Questions': 0.011365383165821152}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(nlp(\"Hey how is it going\")._.cats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conversation' 'Factual Question/Embedding/Crowdsourcing'\n",
      " 'Media Question' 'Recommendation Questions'] [0.06040599 0.04568918 0.87636338 0.01754145]\n",
      "{'Conversation': 0.060405993110324525, 'Factual Question/Embedding/Crowdsourcing': 0.045689179797099216, 'Media Question': 0.876363378829692, 'Recommendation Questions': 0.01754144826288433}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(\"would you be so kind to show me a picture Ali G\")._.cats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Conversation' 'Factual Question/Embedding/Crowdsourcing'\n",
      " 'Media Question' 'Recommendation Questions'] [0.01774493 0.96483208 0.01232319 0.0050998 ]\n",
      "{'Conversation': 0.017744926597209294, 'Factual Question/Embedding/Crowdsourcing': 0.9648320791035818, 'Media Question': 0.012323194924284436, 'Recommendation Questions': 0.005099799374924374}\n"
     ]
    }
   ],
   "source": [
    "print(nlp(\"I bet you have absolutely no idea who is the voice of Tanjirou in  Kimetsu no Yaiba\")._.cats)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
